# **End-to-End Stock Data Handling and Prediction Project**  

## **Overview**  
This project demonstrates a complete data pipeline for handling stock data. It starts by taking user input for a stock ticker through a **Streamlit** web application, fetching historical data from **Yahoo Finance (yfinance)**, storing it in a **MySQL database**, and then applying machine learning and natural language processing for insights.  

Key features include:  
1. **Historical Data Handling**: Downloading and storing stock data in a database.  
2. **Price Prediction**: Using **XGBoost** to predict the next day’s stock price.  
3. **Recommendation System**: Leveraging a **Large Language Model (LLM)** to provide a textual recommendation on the selected stock ticker.  

---

## **Features**  
- **Streamlit UI**: An interactive and user-friendly interface for entering stock tickers.  
- **Data Retrieval**: Automated data fetching using **yfinance**.  
- **Database Integration**: Storing data in **MySQL** for structured storage and analysis.  
- **Machine Learning**: Next-day price prediction using **XGBoost**.  
- **LLM-Based Analysis**: Contextual insights and recommendations generated by a Large Language Model.  

---

## **Technologies Used**  
- **Frontend**: [Streamlit](https://streamlit.io/)  
- **Data Retrieval**: [yfinance](https://pypi.org/project/yfinance/)  
- **Database**: [MySQL](https://www.mysql.com/)  
- **Machine Learning**: [XGBoost](https://xgboost.readthedocs.io/)  
- **Natural Language Processing**: [Ollama](https://ollama.com/)

---

## **How It Works**  
1. **User Input**:  
   - The user enters a stock ticker symbol (e.g., AAPL, MSFT) in the Streamlit application.  

2. **Data Fetching**:  
   - The application fetches historical stock data for the entered ticker from **Yahoo Finance**.  

3. **Price Prediction**:  
   - **XGBoost** is used to analyze historical data and predict the stock's next-day price.  

4. **Recommendation**:  
   - The application queries an **LLM** to generate a recommendation or insight about the stock based on the retrieved data.  

5. **Data Storage**:  
   - Retrieved data is stored in a **MySQL database** for further analysis and persistence.  
---

## **Setup Instructions**  

### **1. Prerequisites**  
Ensure you have the following installed:  
- Python 3.13.1 (tested)  
- MySQL
- ollama with llama3.2:1b

### **2. Clone the Repository**  
```bash  
git clone https://github.com/GovindTV/End-to-End-Data-Handling-Project.git  
cd End-to-End-Data-Handling-Project  
```  

### **3. Install Dependencies**  
Install the required Python packages:  
```bash  
pip install -r requirements.txt  
```  

### **4. Set Up MySQL Database**  
1. Create a new MySQL database.  
2. Update the database credentials in `config.py` or `.env`.  
3. Initialize the database schema:  
   ```bash  
   python 1.setup.py  
   ```  

### **5. Run the Application**  
Launch the Streamlit app:  
```bash  
streamlit run 2.streamlit_app.py  
```  

---


## **Future Enhancements**  
- Store db creds safely in .env file and update the script to use it. 
- Integration with additional data sources.  
- Deployment of the application on a cloud platform (e.g., AWS, Azure, GCP).
- Dockerization for easier sharing.
- Use AI as a data transformation layer.

## **Contact**  
For any questions or feedback, feel free to reach out:  
[**LinkedIn**](https://linkedin.com/in/govindtv)  
[**GitHub**](https://github.com/GovindTV)  

---

Does this meet your expectations? Let me know if you’d like any tweaks or have any opinions!
